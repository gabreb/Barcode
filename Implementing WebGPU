<!DOCTYPE html>
<html>
<head></head>
<body style="margin:0;overflow:hidden;position:relative">
  <div id="rate" style="position:absolute;top:10px;left:10px;color:red;font:16px monospace;background:rgba(0,0,0,0.5);padding:4px;z-index:1"></div>
  <canvas id="gpu-canvas"></canvas>
  <video id="video" autoplay muted playsinline style="display:none"></video>
  <script type="module">
    console.clear();
    async function init() {
      const video = document.getElementById('video');
      video.srcObject = await navigator.mediaDevices.getUserMedia({ video: true });
      await new Promise(r => video.addEventListener('loadedmetadata', r));
      video.play();

      const canvas = document.getElementById('gpu-canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();
      const context = canvas.getContext('webgpu');
      const format = 'bgra8unorm';
      context.configure({ device, format, alphaMode: 'opaque' });

      const sampler = device.createSampler({ magFilter: 'linear', minFilter: 'linear' });
      const videoTexture = device.createTexture({
        size: [canvas.width, canvas.height],
        format,
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT
      });

      // Quad shader for rendering the video texture
      const quadModule = device.createShaderModule({ code: `
@vertex fn vs(@builtin(vertex_index)i:u32)->@builtin(position)vec4<f32>{
  var p=array<vec2<f32>,4>(vec2(-1,-1),vec2(1,-1),vec2(-1,1),vec2(1,1));
  return vec4(p[i],0,1);
}
@group(0) @binding(0) var t:texture_2d<f32>;
@group(0) @binding(1) var s:sampler;
@fragment fn fs(@builtin(position)c:vec4<f32>)->@location(0)vec4<f32>{
  return textureSample(t,s,c.xy/vec2(${canvas.width}.0,${canvas.height}.0));
}` });

      const quadPipeline = device.createRenderPipeline({
        layout: 'auto',
        vertex: { module: quadModule, entryPoint: 'vs' },
        fragment: { module: quadModule, entryPoint: 'fs', targets: [{ format }] },
        primitive: { topology: 'triangle-strip' }
      });

      const quadBG = device.createBindGroup({
        layout: quadPipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: videoTexture.createView() },
          { binding: 1, resource: sampler }
        ]
      });

      // Rectangle shader (semi-transparent green)
      const rectModule = device.createShaderModule({ code: `
@vertex fn vs(@location(0) pos: vec2<f32>) -> @builtin(position) vec4<f32> {
  return vec4(pos, 0.0, 1.0);
}
@fragment fn fs() -> @location(0) vec4<f32> {
  return vec4(0.0, 1.0, 0.0, 0.2); // Semi-transparent green
}` });

      const rectPipeline = device.createRenderPipeline({
        layout: 'auto',
        vertex: {
          module: rectModule,
          entryPoint: 'vs',
          buffers: [{
            arrayStride: 8,
            attributes: [{ shaderLocation: 0, offset: 0, format: 'float32x2' }]
          }]
        },
        fragment: {
          module: rectModule,
          entryPoint: 'fs',
          targets: [{
            format,
            blend: {
              color: {
                srcFactor: 'src-alpha',
                dstFactor: 'one-minus-src-alpha',
                operation: 'add'
              },
              alpha: {
                srcFactor: 'one',
                dstFactor: 'one-minus-src-alpha',
                operation: 'add'
              }
            }
          }]
        },
        primitive: { topology: 'triangle-strip' }
      });

      const rectVerts = new Float32Array([
        -0.4, -0.4,
         0.4, -0.4,
        -0.4,  0.4,
         0.4,  0.4
      ]);

      const rectVB = device.createBuffer({
        size: rectVerts.byteLength,
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
      });
      device.queue.writeBuffer(rectVB, 0, rectVerts);

      const rateDisplay = document.getElementById('rate');
      let last = performance.now();

      async function frame() {
        const now = performance.now();
        const rate = (4 /* verts */) * 1000 / (now - last);
        last = now;

        device.queue.copyExternalImageToTexture(
          { source: video },
          { texture: videoTexture },
          [canvas.width, canvas.height]
        );

        const commandEncoder = device.createCommandEncoder();
        const pass = commandEncoder.beginRenderPass({
          colorAttachments: [{
            view: context.getCurrentTexture().createView(),
            loadOp: 'clear',
            clearValue: { r: 0, g: 0, b: 0, a: 1 },
            storeOp: 'store'
          }]
        });

        // Draw video
        pass.setPipeline(quadPipeline);
        pass.setBindGroup(0, quadBG);
        pass.draw(4);

        // Draw semi-transparent green rectangle
        pass.setPipeline(rectPipeline);
        pass.setVertexBuffer(0, rectVB);
        pass.draw(4);

        pass.end();
        device.queue.submit([commandEncoder.finish()]);

        rateDisplay.textContent = `Vertex/sec: ${rate.toFixed(2)}`;
        requestAnimationFrame(frame);
      }

      requestAnimationFrame(frame);
    }
    init();
  </script>
</body>
</html>
